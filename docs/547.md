# Java NIO:非阻塞服务器

> 原文:[https://jen kov . com/tutorials/Java-nio/non-blocking-server . html](https://jenkov.com/tutorials/java-nio/non-blocking-server.html)

即使你理解 Java NIO 非阻塞特性是如何工作的(`Selector`、`Channel`、`Buffer`等)。)，设计一个无阻塞的服务器还是比较辛苦的。与阻塞 IO 相比，非阻塞 IO 面临几个挑战。本非阻塞服务器教程将讨论非阻塞服务器的主要挑战，并描述一些潜在的解决方案。

很难找到关于设计无阻塞服务器的好信息。因此，本教程中提供的解决方案是基于我自己的工作和想法。如果你有一些替代或更好的想法，我会很高兴听到他们！你可以在文章下写评论或者给我发邮件(见我们的[关于页面](http://jenkov.com/about/index.html))，或者[在 Twitter 上抓住我](https://twitter.com/jjenkov)。

本教程中描述的思想是围绕 Java NIO 设计的。然而，我相信这些思想可以在其他语言中重用，只要它们有某种类似于`Selector`的结构。据我所知，这样的结构是由底层操作系统提供的，所以你很有可能也能在其他语言中获得。

## 非阻塞服务器- GitHub 存储库

我已经创建了一个简单的本教程中介绍的概念的证明，并把它放在 GitHub 库中供您查看。以下是 GitHub 库:

[https://github.com/jjenkov/java-nio-server](https://github.com/jjenkov/java-nio-server)

## 非阻塞 IO 管道

*非阻塞 IO 管道*是处理非阻塞 IO 的组件链。这包括以非阻塞方式读写 IO。下面是一个简化的非阻塞 IO 管道的图示:

![A simplified non-blocking IO pipeline.](../Images/632e378a81a96d1be9870b51f3f24568.png)

一个组件使用一个[选择器](/java-nio/selectors.html)来检查一个[通道](/java-nio/channels.html)何时有数据要读取。然后，组件读取输入数据，并根据输入生成一些输出。输出再次被写入一个`Channel`。

非阻塞 IO 管道不需要同时读取和写入数据。有些管道可能只读取数据，有些管道可能只写入数据。

上图只显示了一个组件。一个非阻塞 IO 流水线可能有多个组件处理输入数据。非阻塞 IO 管道的长度取决于管道需要做什么。

非阻塞 IO 管道也可能同时从多个`Channel`读取。例如，从多个`SocketChannel`读取数据。

上图中的控制流也被简化了。该组件通过`Selector`启动从`Channel`读取数据。不是`Channel`将数据推入`Selector`并从那里推入组件，即使这是上图所建议的。

## 非阻塞与阻塞 IO 管道

非阻塞和阻塞 IO 管道的最大区别是如何从底层`Channel`(套接字或文件)读取数据。

IO 管道通常从一些流(从套接字或文件)中读取数据，并将这些数据分成连贯的消息。这类似于使用令牌化器将数据流分解成令牌进行解析。相反，您将数据流分解成更大的消息。我将调用将流分解成消息的组件，用于*消息阅读器*。下面是一个消息读取器将流分解成消息的图示:

![A Message Reader breaking a stream into messages.](../Images/84397ac00a7c870f01693572bfd0ebc2.png)

一个阻塞的 IO 流水线可以使用一个类似于`InputStream`的接口，一次可以从底层`Channel`读取一个字节，类似于`InputStream`的接口阻塞，直到有数据准备好读取。这导致消息读取器实现阻塞。

对流使用阻塞 IO 接口大大简化了消息阅读器的实现。阻塞消息读取器永远不必处理没有从流中读取数据的情况，或者只从流中读取了部分消息并且需要稍后恢复消息解析的情况。

类似地，阻塞消息编写器(向流中写入消息的组件)永远不必处理只写入部分消息的情况，以及稍后必须恢复消息写入的情况。

### 阻止 IO 管道缺陷

虽然阻塞消息读取器更容易实现，但它有一个不幸的缺点，即需要为每个需要拆分成消息的流创建一个单独的线程。这是必要的，因为每个流的 IO 接口都会阻塞，直到有一些数据要从中读取。这意味着单个线程不能尝试从一个流中读取数据，如果没有数据，就从另一个流中读取。一旦线程试图从流中读取数据，线程就会阻塞，直到实际上有一些数据要读取。

如果 IO 管道是必须处理大量并发连接的服务器的一部分，那么服务器的每个活动传入连接都需要一个线程。如果服务器在任何时候都只有几百个并发连接，这可能不是问题。但是，如果服务器有数百万个并发连接，这种类型的设计就不能很好地扩展。每个线程将为其堆栈占用 320K (32 位 JVM)到 1024K (64 位 JVM)的内存。所以，1.000.000 个线程将占用 1 TB 内存！这是在服务器使用任何内存来处理传入消息之前(例如，为消息处理期间使用的对象分配的内存)。

为了减少线程的数量，许多服务器使用一种设计，其中服务器保持一个线程池(例如 100 个)，该线程池一次一个地从入站连接读取消息。入站连接保存在队列中，线程按照入站连接放入队列的顺序处理来自每个入站连接的消息。该设计如下图所示:

![A pool of threads reading messages from streams in a queue.](../Images/03ce8b849c9db83d8ff16f029fd4f851.png)

然而，这种设计要求入站连接相当频繁地发送数据。如果入站连接可能长时间处于非活动状态，那么大量的非活动连接实际上可能会阻塞线程池中的所有线程。这意味着服务器响应变慢，甚至没有响应。

一些服务器设计试图通过在线程池中增加线程数量来缓解这个问题。例如，如果线程池用完了线程，线程池可能会启动更多的线程来处理负载。这种解决方案意味着需要更多的慢速连接来使服务器无响应。但是请记住，您可以运行的线程数量仍然有一个上限。因此，这对于 1.000.000 慢速连接来说不太适用。

## 基本无阻塞 IO 流水线设计

非阻塞 IO 管道可以使用单线程从多个流中读取消息。这要求流可以切换到非阻塞模式。在非阻塞模式下，当您试图从流中读取数据时，流可能会返回 0 个或更多字节。如果流中没有要读取的数据，则返回 0 字节。当流实际上有一些数据要读取时，返回 1+字节。

为了避免检查没有字节要读的流，我们使用了一个 [Java NIO 选择器](/java-nio/selectors.html)。一个或多个`SelectableChannel`实例可以用一个`Selector`注册。当你调用`Selector`上的`select()`或`selectNow()`时，它只给你实际有数据要读取的`SelectableChannel`实例。该设计如下图所示:

![A component selecting channels with data to read.](../Images/1a48fa72fca9e3cb075820a81f526b13.png)

## 阅读部分消息

当我们从一个`SelectableChannel`读取一个数据块时，我们不知道该数据块包含的信息是少还是多。数据块可能包含部分消息(少于一条消息)、完整消息或多于一条消息，例如 1.5 或 2.5 条消息。各种可能的部分消息如下所示:

![A data block can contain less than or more than a single message.](../Images/8839295d01b7993d0534a5f6a906ac28.png)

处理部分消息有两个挑战:

1.  检测数据块中是否有完整的消息。
2.  在其余消息到达之前，如何处理部分消息。

检测完整消息要求消息阅读器查看数据块中的数据，以查看数据是否包含至少一条完整消息。如果数据块包含一个或多个完整的消息，则这些消息可以通过管道向下发送进行处理。寻找完整消息的过程会重复很多次，所以这个过程必须尽可能快。

每当数据块中存在部分消息时，无论是其本身还是在一个或多个完整消息之后，都需要存储该部分消息，直到该消息的其余部分从`Channel`到达。

检测完整消息和存储部分消息都是消息阅读器的责任。为了避免混合来自不同`Channel`实例的消息数据，我们将为每个`Channel`使用一个消息阅读器。设计看起来是这样的:

![A component reading messages via a Message Reader.](../Images/636e7e7270477de3ac364c031d99ef8e.png)

在检索到一个有数据要从`Selector`中读取的`Channel`实例后，与那个`Channel`相关联的消息读取器读取数据并试图将它分解成消息。如果这导致任何完整的消息被读取，这些消息可以通过读取管道传递给任何需要处理它们的组件。

消息阅读器当然是特定于协议的。消息阅读器需要知道它试图阅读的消息的格式。如果我们的服务器实现是跨协议可重用的，它需要能够插入消息阅读器实现——可能通过某种方式接受消息阅读器工厂作为配置参数。

## 存储部分消息

既然我们已经确定了存储部分消息直到收到完整消息是消息阅读器的责任，我们需要弄清楚应该如何实现这种部分消息存储。

我们应该考虑两个设计因素:

1.  我们希望尽可能少地复制消息数据。复制越多，性能越低。
2.  我们希望完整的消息存储在连续的字节序列中，以使解析消息更容易。

### 每个消息读取器一个缓冲区

显然，部分消息需要存储在某种缓冲区中。简单的实现就是在每个消息读取器内部有一个缓冲区。然而，这个缓冲区应该有多大呢？它需要足够大，甚至能够存储最大的允许消息。因此，如果允许的最大消息是 1MB，那么每个消息读取器中的内部缓冲区至少需要 1MB。

当我们达到数百万个连接时，每个连接使用 1MB 实际上不起作用。1.000.000 x 1MB 还是 1TB 内存！如果最大邮件大小是 16MB 呢？还是 128MB？

### 可调整大小的缓冲区

另一种选择是实现一个可调整大小的缓冲区，供每个消息阅读器内部使用。可调整大小的缓冲区开始时很小，如果消息变得太大，缓冲区就会扩展。这样，每个连接将不一定需要例如 1MB 的缓冲器。每个连接只占用保存下一条消息所需的内存。

有几种方法可以实现可调整大小的缓冲区。它们都有优点和缺点，所以我将在下面的部分中讨论它们。

### 通过复制调整大小

实现可调整大小的缓冲器的第一种方式是从例如 4KB 的小缓冲器开始。如果一个消息不适合 4KB 的缓冲区，可以分配一个更大的缓冲区，例如 8KB，并将 4KB 缓冲区中的数据复制到更大的缓冲区中。

通过复制调整缓冲区大小的优点是，消息的所有数据都保存在一个连续的字节数组中。这使得解析消息更加容易。

resize-by-copy 缓冲区实现的缺点是，对于较大的消息，它会导致大量的数据复制。

为了减少数据复制，您可以分析流经系统的消息的大小，找到一些可以减少复制量的缓冲区大小。例如，您可能会看到大多数消息都小于 4KB，因为它们只包含非常小的请求/响应。这意味着第一个缓冲区的大小应该是 4KB。

然后，您可能会看到，如果一条消息大于 4KB，通常是因为它包含一个文件。您可能会注意到，流经系统的大多数文件都小于 128KB。那么将第二个缓冲区的大小设为 128KB 是有意义的。

最后，您可能会看到，一旦消息超过 128KB，消息的大小就没有真正的模式了，所以最终的缓冲区大小应该是最大的消息大小。

有了基于流经系统的消息大小的这三个缓冲区大小，您将在一定程度上减少数据复制。4KB 以下的邮件将不会被复制。对于 1.000.000 个并发连接，结果是 1.000.000 x 4KB = 4GB，这在当今(2015 年)的大多数服务器中都是可能的。4KB 到 128KB 之间的消息将被复制一次，只有 4KB 的数据需要复制到 128KB 的缓冲区中。介于 128KB 和最大邮件大小之间的邮件将被复制两次。第一次复制 4KB，第二次复制 128KB，因此对于最大的邮件，总共复制 132KB。假设没有太多超过 128KB 的消息，这可能是可以接受的。

一旦消息被完全处理，分配的内存应该被再次释放。这样，从同一连接接收的下一条消息又会以最小的缓冲区大小开始。这是必要的，以确保内存可以在连接之间更有效地共享。很可能不是所有的连接都同时需要大的缓冲区。

关于如何实现这样一个支持可调整大小数组的内存缓冲区，我在这里有一个完整的教程:[可调整大小数组](/java-performance/resizable-array.html)。本教程还包含一个到 GitHub 存储库的链接，其中的代码展示了一个有效的实现。

### 通过追加调整大小

调整缓冲区大小的另一种方法是让缓冲区由多个数组组成。当需要调整缓冲区时，只需分配另一个字节数组并将数据写入其中。

有两种方法可以形成这样的缓冲区。一种方法是分配单独的字节数组，并保存这些字节数组的列表。另一种方法是分配更大的共享字节数组的片，然后保存分配给缓冲区的片的列表。我个人觉得切片方法稍微好一点，但是差别不大。

通过向缓冲区附加单独的数组或片来增大缓冲区的优点是，在写入期间不需要复制任何数据。所有数据都可以直接从一个套接字(`Channel`)直接复制到一个数组或切片中。

以这种方式增大缓冲区的缺点是，数据不是存储在单个连续的数组中。这使得消息解析更加困难，因为解析器需要同时寻找每个单独数组的结尾和所有数组的结尾。因为您需要在书面数据中寻找消息的结尾，所以这个模型不太容易使用。

### TLV 编码信息

一些协议消息格式使用 TLV 格式(类型、长度、值)进行编码。这意味着，当消息到达时，消息的总长度存储在消息的开头。这样，您就可以立即知道为整个消息分配多少内存。

TLV 编码使得内存管理更加容易。您可以立即知道为该消息分配多少内存。在只被部分使用的缓冲区的末端，没有内存被浪费。

TLV 编码的一个缺点是，在消息的所有数据到达之前，就为消息分配了所有的内存。一些发送大消息的慢速连接会占用你所有的可用内存，使你的服务器没有反应。

解决此问题的一个方法是使用包含多个 TLV 字段的消息格式。因此，内存是为每个字段分配的，而不是为整个消息分配的，只有当字段到达时才分配内存。不过，大字段对内存管理的影响和大消息一样。

另一种解决方法是对在例如 10-15 秒内没有接收到的消息进行超时。这可以使您的服务器从许多大消息的巧合、同时到达中恢复过来，但是仍然会使服务器在一段时间内没有响应。此外，蓄意的 DoS(拒绝服务)攻击仍然会导致服务器内存的完全分配。

TLV 编码存在不同的变体。具体使用多少字节来指定字段的类型和长度取决于每个单独的 TLV 编码。还有一些 TLV 编码，首先是字段的长度，然后是类型，最后是值(一种 LTV 编码)。虽然字段的顺序不同，但它仍然是 TLV 的变体。

TLV 编码使得内存管理更加容易，这也是 HTTP 1.1 是如此糟糕的协议的原因之一。这是他们试图在 HTTP 2.0 中解决的问题之一，在 HTTP 2.0 中，数据以 LTV 编码的帧传输。这也是为什么我们为我们的[VStack.co 项目](http://vstack.co)设计了我们自己的网络协议，它使用 TLV 编码。

## 编写部分消息

在非阻塞 IO 流水线中，写数据也是一个挑战。当你在非阻塞模式下调用`Channel`上的`write(ByteBuffer)`时，不能保证`ByteBuffer`中有多少字节正在被写入。`write(ByteBuffer)`方法返回写入了多少字节，因此可以跟踪写入的字节数。这就是挑战:跟踪部分写入的消息，以便最终消息的所有字节都被发送出去。

为了管理向`Channel`写入部分消息，我们将创建一个消息写入器。就像消息阅读器一样，我们需要一个消息写入器来写入消息。在每个消息编写器中，我们精确地记录了当前正在编写的消息已经被写入了多少字节。

如果到达消息编写器的消息多于它可以直接写到`Channel`的消息，则消息需要在消息编写器内部排队。然后，消息编写器尽可能快地将消息写入`Channel`。

下面的图表显示了到目前为止部分消息编写是如何设计的:

![A component sending messages to a Message Writer which queue them up and send them to a Channel.](../Images/66873043dabb276ab5052eb0fee67bcb.png)

为了使消息编写器能够发送之前只发送了一部分的消息，需要不时地调用消息编写器，以便它能够发送更多的数据。

如果您有很多连接，您将有很多消息编写器实例。检查例如一百万个消息编写器实例以查看它们是否可以写入任何数据是缓慢的。首先，许多消息编写器实例可能没有任何消息要发送。我们不想检查那些消息编写器实例。其次，并非所有的`Channel`实例都准备好写入数据。我们不想浪费时间试图将数据写入一个无论如何都不能接受任何数据的`Channel`。

要检查`Channel`是否准备好写入，您可以用`Selector`注册通道。然而，我们并不想用`Selector`注册所有的`Channel`实例。想象一下，如果您有 1000000 个连接，其中大部分是空闲的，并且所有 1000000 个连接都向`Selector`注册了。然后，当您调用`select()`时，这些`Channel`实例中的大部分将是写就绪的(它们大部分是空闲的，记得吗？).然后，您必须检查所有这些连接的消息编写器，以查看它们是否有任何数据要写入。

为了避免检查所有消息编写器实例的消息，以及没有任何消息要发送给它们的所有`Channel`实例，我们使用这个两步方法:

1.  当消息被写入消息编写器时，消息编写器将其关联的`Channel`注册到`Selector`(如果尚未注册)。
    T3】
2.  当您的服务器有时间时，它会检查`Selector`以查看哪些注册的`Channel`实例已经准备好写入。对于每个写就绪的`Channel`，其相关的消息写入器被请求向`Channel`写入数据。如果消息编写者将其所有消息写入其`Channel`，则`Channel`将再次从`Selector`中注销。

这个小的两步方法确保了只有那些有消息被写入的`Channel`实例实际上被注册到了`Selector`。

## 把所有的放在一起

正如您所看到的，非阻塞服务器需要不时地检查传入的数据，以查看是否接收到任何新的完整消息。服务器可能需要检查多次，直到收到一个或多个完整的消息。检查一次是不够的。

类似地，非阻塞服务器需要不时地检查是否有数据要写入。如果是，服务器需要检查是否有任何相应的连接准备好将数据写入其中。仅在消息第一次排队时进行检查是不够的，因为消息可能是部分写入的。

总而言之，非阻塞服务器最终有三个需要定期执行的“管道”:

*   从打开的连接中检查新的传入数据的读取管道。
*   处理收到的所有完整消息的进程管道。
*   写管道，检查是否可以将任何传出消息写入任何打开的连接。

这三个管道在一个循环中重复执行。您也许能够在某种程度上优化执行。例如，如果没有排队的消息，您可以跳过写管道。或者，如果我们没有收到新的，完整的消息，也许你可以跳过处理管道。

下图展示了完整的服务器循环:

![The full server loop of a non-blocking server.](../Images/99c2c50815fba39548a782301b81c0d3.png)

如果您仍然觉得这有点复杂，请记得查看 GitHub 资源库:

[https://github.com/jjenkov/java-nio-server](https://github.com/jjenkov/java-nio-server)

也许看到运行中的代码会帮助您理解如何实现这一点。

## 服务器线程模型

GitHub 存储库中的非阻塞服务器实现使用一个具有两个线程的线程模型。第一个线程接受来自`ServerSocketChannel`的输入连接。第二个线程处理接受的连接，即读取消息、处理消息并将响应写回到连接。这种双线程模型如下所示:

![The 2 thread model for the non-blocking server implemented in the GitHub repository.](../Images/64b33dc7e8eb5692342c06ab6c7c2776.png)

上一节中解释的服务器处理循环由处理线程执行。